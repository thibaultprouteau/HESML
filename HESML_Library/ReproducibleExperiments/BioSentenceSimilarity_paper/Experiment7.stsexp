<?xml version="1.0" encoding="UTF-8"?>
<!-- edited with XMLSPY v5 U (http://www.xmlspy.com) by Ramon Yepes (Investronica) -->
<!-- This experiment evaluates the impact of stop words in string-based STS measures -->
<SentenceSimilarityExperiments xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../SentenceSimilarityExperiments.xsd">
	<SingleDatasetSentenceSimilarityValuesExperiment>
		<OutputFilename>raw_similarity_BIOSSES.csv</OutputFilename>
		<DatasetDirectory>../SentenceSimDatasets</DatasetDirectory>
		<DatasetFilename>BIOSSESNormalized.tsv</DatasetFilename>
		<SentenceSimilarityMeasures>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

		</SentenceSimilarityMeasures>
	</SingleDatasetSentenceSimilarityValuesExperiment>
	<SingleDatasetSentenceSimilarityValuesExperiment>
		<OutputFilename>raw_similarity_MedSTSFull.csv</OutputFilename>
		<DatasetDirectory>../SentenceSimDatasets</DatasetDirectory>
		<DatasetFilename>MedStsFullNormalized.tsv</DatasetFilename>
		<SentenceSimilarityMeasures>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			
		</SentenceSimilarityMeasures>
	</SingleDatasetSentenceSimilarityValuesExperiment>
	<SingleDatasetSentenceSimilarityValuesExperiment>
		<OutputFilename>raw_similarity_CTR.csv</OutputFilename>
		<DatasetDirectory>../SentenceSimDatasets</DatasetDirectory>
		<DatasetFilename>CTRNormalized_averagedScore.tsv</DatasetFilename>
		<SentenceSimilarityMeasures>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bio_embedding_extrinsic</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioWordVec_extrinsic Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>BioWordVecBinaryWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>BioNLP2016_PubMed-shuffle-win-30.bin</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>BioNLP2016_PubMed-shuffle-win-30 Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			
		</SentenceSimilarityMeasures>
	</SingleDatasetSentenceSimilarityValuesExperiment>
</SentenceSimilarityExperiments>