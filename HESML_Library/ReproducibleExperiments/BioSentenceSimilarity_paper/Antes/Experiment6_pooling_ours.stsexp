<?xml version="1.0" encoding="UTF-8"?>
<!-- edited with XMLSPY v5 U (http://www.xmlspy.com) by Ramon Yepes (Investronica) -->
<!-- This experiment evaluates the impact of stop words in string-based STS measures -->
<SentenceSimilarityExperiments xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../SentenceSimilarityExperiments.xsd">
	<SingleDatasetSentenceSimilarityValuesExperiment>
		<OutputFilename>raw_similarity_BIOSSES_experiment6_pooling_ours.csv</OutputFilename>
		<DatasetDirectory>../SentenceSimDatasets</DatasetDirectory>
		<DatasetFilename>BIOSSESNormalized.tsv</DatasetFilename>
		<SentenceSimilarityMeasures>
			
			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			

		</SentenceSimilarityMeasures>
	</SingleDatasetSentenceSimilarityValuesExperiment>
	<SingleDatasetSentenceSimilarityValuesExperiment>
		<OutputFilename>raw_similarity_MedSTSFull_experiment6_pooling_ours.csv</OutputFilename>
		<DatasetDirectory>../SentenceSimDatasets</DatasetDirectory>
		<DatasetFilename>MedStsFullNormalized.tsv</DatasetFilename>
		<SentenceSimilarityMeasures>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			
		</SentenceSimilarityMeasures>
	</SingleDatasetSentenceSimilarityValuesExperiment>
	<SingleDatasetSentenceSimilarityValuesExperiment>
		<OutputFilename>raw_similarity_CTR_experiment6_pooling_ours.csv</OutputFilename>
		<DatasetDirectory>../SentenceSimDatasets</DatasetDirectory>
		<DatasetFilename>CTRNormalized_averagedScore.tsv</DatasetFilename>
		<SentenceSimilarityMeasures>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_defaultchar.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_defaultchar Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>bioc_skipgram_Nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>bioc_skipgram_Nonechar200dim Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>None</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>

			<SWEMMeasure>
				<Pooling>Average</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Average</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Max</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Max</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Min</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Min</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			<SWEMMeasure>
				<Pooling>Sum</Pooling>
				<WordEmbeddingFileFormat>FastTextVecWordEmbedding</WordEmbeddingFileFormat>
				<PretrainedModelFilename>stanford_skipgram_nonechar200dim.vec</PretrainedModelFilename>
				<PretrainedModelDirectory>../WordEmbeddings</PretrainedModelDirectory>
				<Label>stanford_skipgram_nonechar200dim Sum</Label>
				<WordProcessing>
					<StopWordsFileDir>../StopWordsFiles</StopWordsFileDir>
					<StopWordsFilename>NoneStopWords.txt</StopWordsFilename>
					<TokenizerType>BioCNLPTokenizer</TokenizerType>
					<LowercaseNormalization>true</LowercaseNormalization>
					<CharFilteringType>Default</CharFilteringType>
				</WordProcessing>
			</SWEMMeasure>
			
		</SentenceSimilarityMeasures>
	</SingleDatasetSentenceSimilarityValuesExperiment>
</SentenceSimilarityExperiments>
